{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06808177-d5de-4a27-a51f-e93f55bcc413",
   "metadata": {},
   "source": [
    "# SQL Remove Duplicates: Comprehensive Methods and Best Practices\n",
    "\n",
    "\n",
    "Explore the different methods for filtering out and permanently removing duplicate rows using SQL. Learn the practical applications of how to remove duplicates in SQL Server, MySQL, and PostgreSQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7834682e-6608-485f-8378-17f5302a7af8",
   "metadata": {},
   "source": [
    "Duplicate records are a common issue that can compromise data integrity and database performance. Removing these duplicates is essential for maintaining data accuracy, optimizing storage, and improving query performance. In this article, we will explore various techniques for removing duplicate rows in SQL, tailored to various use cases and database management systems.\n",
    "\n",
    "As we get started, I highly recommend taking DataCampâ€™s Introduction to SQL and Learn SQL courses to learn foundational knowledge of extracting and analyzing data using SQL. Also, I find the SQL Basics Cheat Sheet, which you can download, is a helpful reference because it has all the most common SQL functions.\n",
    "\n",
    "#### Understanding Duplicate Rows in SQL\n",
    "\n",
    "Duplicate rows in SQL refer to records within a table that contain identical values across all or selected columns. The common causes of duplicate rows in SQL include the following:\n",
    "\n",
    "- Missing Primary Keys: When tables lack a defined primary key or unique constraint, there is no mechanism to prevent the insertion of duplicate data. This can happen when a table is not normalized and/or there are transitive dependency issues.\n",
    "- Data Integration Issues: When merging datasets from different sources, improper joins or inconsistencies in data formats can accidentally introduce duplicates.\n",
    "- Manual Data Entry Errors: Human error, such as entering the same record multiple times, is another common cause of duplicate rows.\n",
    "In the rest of the article, we will look at how to remove duplicates in SQL, and we will divide the article into two blocks. In the first section, we will cover how to remove duplicates in the data that you are retrieving for a report or dashboard; in the second section, we will look at how to remove duplicates in the database.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e72aa5e-8767-4375-93f4-5e01a4c5a61a",
   "metadata": {},
   "source": [
    "#### Methods for Removing Duplicates in the Data You Retrieve\n",
    "\n",
    "There are different methods of removing duplicates while retrieving records in SQL. Each method depends on the DBMS, such as SQL Server, MySQL, and PostgreSQL. In this section, we will look at the methods of removing duplicates while highlighting any special consideration for each database. Keep in mind, these methods filter the data and return unique records and they do now modify the underlying table.\n",
    "\n",
    "#### Using DISTINCT keyword\n",
    "\n",
    "The DISTINCT keyword is used in a SELECT statement to retrieve unique rows. The DISTINCT keyword syntax for removing duplicates is similar for MySQL, PostgreSQL, and SQL Server databases. The query below will retrieve unique customer names from the customers table.\n",
    "\n",
    "\n",
    "SELECT DISTINCT Name\\\n",
    "FROM customers;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de2a7b8-0a8c-4f6e-bba5-7f3287027b46",
   "metadata": {},
   "source": [
    "#### Using GROUP BY with aggregate functions\n",
    "\n",
    "The GROUP BY clause, combined with other aggregate functions like MAX(), MIN(), or COUNT(), can help remove duplicate records from tables. The GROUP BY clause helps select specific records to retain while deleting other duplicates.\n",
    "\n",
    "Suppose you want to delete duplicate customer records but keep the one with the highest ID. You will use the GROUP BY clause with the MAX() function, as shown below.\n",
    "\n",
    "\n",
    "-- Delete duplicate rows from the 'customers' table (aliased as c1)\\\n",
    "DELETE c1\\\n",
    "FROM customers c1\\\n",
    "-- Find the maximum ID for each unique Name\\\n",
    "JOIN (\\\n",
    "    SELECT Name, MAX(ID) AS MaxID\\\n",
    "    FROM customers\\\n",
    "    GROUP BY Name\\\n",
    ") c2\\\n",
    "-- Match rows based on 'Name' and keep the row with the maximum ID\\\n",
    "ON c1.Name = c2.Name \\\n",
    "AND c1.ID < c2.MaxID;\n",
    "\n",
    "MySQL and SQL Server support the above syntax of GROUP BY with aggregate functions and the JOIN clause. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581f428-86a1-41d4-acdb-677c3358fe36",
   "metadata": {},
   "source": [
    "#### Using ROW_NUMBER() with Common Table Expressions (CTE)\n",
    "\n",
    "With the ROW_NUMBER() function combined with a Common Table Expression (CTE), you can filter out duplicates based on your criteria. The ROW_NUMBER function, when used with PARTITION BY and ORDER BY clauses, assigns a unique sequential number to each row. This method allows for filtering out the rows that do not meet the required criteria.\n",
    "\n",
    "The following query identifies duplicates and removes all but the first occurrence.\n",
    "\n",
    "\n",
    "-- Common Table Expression (CTE) to rank rows based on 'Name'\\\n",
    "WITH CTE AS (\\\n",
    "    SELECT ID, Name, ROW_NUMBER() OVER (PARTITION BY Name ORDER BY ID ASC) AS RowNum\\\n",
    "    FROM customers\\\n",
    ")\\\n",
    "-- Select only the unique records where RowNum = 1\\\n",
    "SELECT ID, Name\\\n",
    "FROM CTE\\\n",
    "WHERE RowNum = 1;\n",
    "\n",
    "This method works well for modern versions of SQL Server, MySQL, and PostgreSQL. It is useful for larger datasets or more complex conditions, as it allows you to specify exactly which duplicate to keep.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc8132-120e-4fe4-8428-81e513570a48",
   "metadata": {},
   "source": [
    "#### Removing duplicates using self-JOIN\n",
    "\n",
    "A self-join allows you to compare a table to itself, making it helpful in identifying and removing duplicate rows by comparing records based on specific criteria. The following example uses the self-join to delete the row with the higher ID, keeping only the first occurrence of each name.\n",
    "\n",
    "\n",
    "-- Delete duplicate rows using self-join\\\n",
    "DELETE c1\\\n",
    "FROM customers c1\\\n",
    "JOIN customers c2\\\n",
    "ON c1.Name = c2.Name AND c1.ID > c2.ID;\n",
    "\n",
    "The above method works in major databases, including SQL server, MySQL, and PostgreSQL. Check out our Intermediate SQL course to learn more about using aggregate functions and joins to filter data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354b373-9513-4798-991d-90d5a23a4c88",
   "metadata": {},
   "source": [
    "#### Methods for Removing Duplicates in the Database\n",
    "\n",
    "While you can remove duplicate records using queries, you can also permanently delete them from the database. This approach is important for maintaining data quality. The following methods are used to remove duplicates from the database.\n",
    "\n",
    "#### Using ROW_NUMBER() and DELETE\n",
    "\n",
    "The ROW_NUMBER() function assigns a sequential number to rows within a defined partition. When used with the DELETE statement, it helps identify duplicates by ranking rows based on specific columns and removing unwanted records. This method applies to modern versions of MySQL (from 8.0), PostgreSQL, and SQL Server.\n",
    "\n",
    "Suppose you want to remove duplicate customer records based on the Name column, keeping only the first occurrence (smallest ID):\n",
    "\n",
    "-- Common Table Expression (CTE) to rank rows based on 'Name'\\\n",
    "WITH CTE AS (\\\n",
    "    SELECT ID, Name, ROW_NUMBER() OVER (PARTITION BY Name ORDER BY ID ASC) AS RowNum\\\n",
    "    FROM customers\\\n",
    ")\n",
    "-- Delete rows from the 'customers' table where the row number is greater than 1\\\n",
    "DELETE FROM customers\\\n",
    "WHERE ID IN (SELECT ID FROM CTE WHERE RowNum > 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31734a0-b709-4974-b2ee-d5b1995f14fd",
   "metadata": {},
   "source": [
    "#### Using DELETE with subquery\n",
    "\n",
    "Sometimes, a simple DELETE operation using a subquery can remove duplicates from the database. This method is suitable for older versions of MySQL or PostgreSQL where ROW_NUMBER() might not be available.\n",
    "\n",
    "The query below deletes rows from the customers table where the ID is not the minimum for each Name, keeping only the row with the smallest ID for each unique Name.\n",
    "\n",
    "\n",
    "-- Delete rows from the 'customers' table\\\n",
    "DELETE FROM customers\\\n",
    "WHERE ID NOT IN (\\\n",
    "    -- Subquery to find the minimum ID for each unique Name\\\n",
    "    SELECT MIN(ID)\\\n",
    "    FROM customers\\\n",
    "    GROUP BY Name\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7216620b-c863-4293-9594-9df990783607",
   "metadata": {},
   "source": [
    "#### Using GROUP BY with HAVING clause\n",
    "\n",
    "When you need to check for duplicate values in specific columns, the GROUP BY clause combined with the HAVING clause can be used to identify duplicates. This method allows you to delete specific rows based on the given criteria. This method is compatible with SQL Server, MySQL, and PostgreSQL.\n",
    "\n",
    "The following query deletes rows from the customers table where the ID belongs to a group of duplicates.\n",
    "\n",
    "\n",
    "-- Delete rows from the 'customers' table where there are duplicates\\\n",
    "DELETE FROM customers\\\n",
    "WHERE ID IN (\\\n",
    "    -- Subquery to find IDs of duplicate rows\\\n",
    "    SELECT ID\\\n",
    "    FROM customers\\\n",
    "    GROUP BY ID\\\n",
    "    HAVING COUNT(*) > 1\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a00e2-07db-45d2-90d0-15f89979621f",
   "metadata": {},
   "source": [
    "#### Using temporary tables for batch processing\n",
    "\n",
    "Temporary tables are efficient for batch processing and removing duplicates in large datasets. This method is useful where single queries can cause performance issues. The following query creates a temporary table to store the minimum ID for each customer_name and delete rows from the customers table where the ID is not in the temp_customers table.\n",
    "\n",
    "\n",
    "-- Create a temporary table\\\n",
    "CREATE TEMPORARY TABLE temp_customers AS\\\n",
    "SELECT MIN(customer_id) AS ID, customer_name\\\n",
    "FROM customers\\\n",
    "GROUP BY customer_name;\\\n",
    "DELETE FROM customers\\\n",
    "WHERE customer_id NOT IN (SELECT ID FROM temp_customers);\n",
    "\n",
    "The above syntax using CREATE TEMPORARY TABLE is only supported in MySQL and PostgreSQL databases. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049557d-e0ca-4d2e-9648-7a9048a19a36",
   "metadata": {},
   "source": [
    "## Remove Duplicates in SQL Server\n",
    "\n",
    "SQL Server offers different methods of removing duplicate records from the database. These methods include using DISTINCT with INTO, ROW_NUMBER(), and temporary tables. \n",
    "\n",
    "#### Using DISTINCT with INTO\n",
    "\n",
    "You can use the DISTINCT keyword in a SELECT statement to create a new table with unique records. You can drop the old table once you verify the new table has the specified records. The following example creates the unique_customers table with unique records from the customers table.\n",
    "\n",
    "\n",
    "-- Select distinct rows from 'customers' and create a new table 'unique_customers'\\\n",
    "SELECT DISTINCT *\\\n",
    "INTO unique_customers\\\n",
    "FROM customers;\\\n",
    "-- Drop the original 'customers' table to remove it from the database\\\n",
    "DROP TABLE customers;\\\n",
    "-- Rename the 'unique_customers' table to 'customers' to replace the original table\\\n",
    "EXEC sp_rename 'unique_customers', 'customers';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc38be1-7d78-4eea-9222-34f799072b91",
   "metadata": {},
   "source": [
    "#### Using ROW_NUMBER()\n",
    "\n",
    "You can also use the ROW_NUMBER() function to remove duplicate records from the SQL Server. Assume you have a Customers table with duplicate rows based on the CustomerName column, and you want to delete all but the first occurrence for each duplicate group.\n",
    "\n",
    "\n",
    "-- Common Table Expression (CTE) to assign a row number to each customer \\\n",
    "WITH CTE AS (\n",
    "    SELECT CustomerID, CustomerName, ROW_NUMBER() OVER (PARTITION BY CustomerName ORDER BY CustomerID ASC) AS RowNum\\\n",
    "    FROM Customers\n",
    ")\\\n",
    "-- Delete rows from the CTE\\\n",
    "DELETE FROM CTE\\\n",
    "WHERE RowNum > 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6135dea9-8a74-4215-8b9c-f5c0a7fdc336",
   "metadata": {},
   "source": [
    "#### Using temporary table\n",
    "\n",
    "Since SQL Server does not support the CREATE TEMPORARY TABLE function, you use the SELECT INTO function. Temporary tables in SQL Server use # as a prefix for the table name.\n",
    "\n",
    "\n",
    "-- Create a temporary table\\\n",
    "SELECT MIN(CustomerID) AS ID, CustomerName\\\n",
    "INTO #temp_customers\\\n",
    "FROM customers\\\n",
    "GROUP BY CustomerName;\\\n",
    "-- Delete rows from the 'customers' table where the ID is not in the temporary table\\\n",
    "DELETE FROM customers\\\n",
    "WHERE CustomerIDNOT IN (SELECT ID FROM #temp_customers);\\\n",
    "-- Optionally drop the temporary table after use\\\n",
    "DROP TABLE #temp_customers;\n",
    "\n",
    "I suggest trying our SQL Server Fundamentals skill track to improve your joining tables and data analysis skills. The SQL Server Developer career track will equip you with the skills to write, troubleshoot, and optimize your queries using SQL Server.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b1842-60c6-4aa0-abea-e6026f0685dc",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "Duplicate rows are a common problem affecting data quality and database performance. Consider the following best practices to prevent duplicate records from being inserted in your database.\n",
    "\n",
    "- Use Primary Keys: The primary key column ensures that each record contains unique information, preventing duplicate values from entering the table.\n",
    "- Implement Unique Constraints: Applying unique constraints to any column ensures no duplicates exist across non-primary key columns, such as email addresses or phone numbers.\n",
    "- Proper Database Design and Normalization: Effective schema design and database normalization help reduce redundancy and duplicate data. This approach ensures each record is stored in specific tables.\n",
    "- Use Unique Indexes: Use unique indexes to ensure that certain column combinations are unique without requiring full table-level constraints across the entire dataset.\n",
    "- Regular Data Audits: Perform regular data audits by running queries to identify potential duplicates based on your business rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dae5e6-4776-46e3-8478-23994d892972",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Identifying and removing duplicate rows is important to maintaining database efficiency and data accuracy. It is always a best practice to back up your data before making modifications to ensure no accidental data loss occurs.\n",
    "\n",
    "If you are interested in becoming a proficient data analyst, check out our Associate Data Analyst in SQL career track to learn the necessary skills. The Reporting in SQL course is also appropriate if you want to learn how to build professional dashboards using SQL. Finally, I recommend obtaining the SQL Associate Certification to demonstrate your mastery of using SQL for data analysis and stand out among other data professionals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5c159-3215-418b-aa24-a0b3944015de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eee56ee0-c77b-4621-adcb-821604841e98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
